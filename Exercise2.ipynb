{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0efcc2bf",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec028a",
   "metadata": {},
   "source": [
    "*In this Exercise we work on the Simlex-999 dataset which gives the similarity score between two words and we compare it with the pretrained 300-dimensional word2vec embeddings from Google using gensim and find the similarity scores from this embeddings and solving the euclidean distance between two words and compare the similarity using the p test* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e310554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509107f8",
   "metadata": {},
   "source": [
    "*We build the reader function for reading in from .vecs files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73927c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dataset_reader(path):\n",
    "    \n",
    "    words1 = []\n",
    "    words2 = []\n",
    "    POSs = []\n",
    "    SimLex999s = []\n",
    "    concs_w1 = []\n",
    "    concs_w2 = []\n",
    "    concQs = []\n",
    "    Assoc_USFs = []\n",
    "    SimAssocs333 = []\n",
    "    SD_SimLexs = []\n",
    "    rows = []\n",
    "    \n",
    "    with open(path, \"r\") as f:\n",
    "            next(f)\n",
    "            for line in f:\n",
    "                word1, word2, POS, SimLex999, conc_w1, conc_w2, concQ, Assoc_USF, SimAssoc333, SD_SimLex = line.split('\\t')\n",
    "                words1.append(word1)\n",
    "                words2.append(word2)\n",
    "                POSs.append(POS)\n",
    "                SimLex999 = np.array(SimLex999.split(), dtype='float')\n",
    "                SimLex999s.append(SimLex999)\n",
    "                conc_w1 = np.array(conc_w1.split(), dtype='float')\n",
    "                concs_w1.append(conc_w1)\n",
    "                conc_w2 = np.array(conc_w2.split(), dtype='float')\n",
    "                concs_w2.append(conc_w2)\n",
    "                concQ = np.array(concQ.split(), dtype='float')\n",
    "                concQs.append(concQ)\n",
    "                Assoc_USF = np.array(Assoc_USF.split(), dtype='float')\n",
    "                Assoc_USFs.append(Assoc_USF)\n",
    "                SimAssoc333 = np.array(SimAssoc333.split(), dtype='float')\n",
    "                SimAssocs333.append(SimAssoc333)\n",
    "                SD_SimLex = np.array(SD_SimLex.split(), dtype='float')\n",
    "                SD_SimLexs.append(SD_SimLex)\n",
    "            \n",
    "            strings = np.concatenate((np.array(words1,dtype=str).reshape(len(words1),1),np.array(words2,dtype=str).reshape(len(words1),1),np.array(POSs,dtype=str).reshape(len(words1),1)),axis=1)\n",
    "            numbers = np.concatenate((np.array(SimLex999s).reshape(len(words1),1),np.array(concs_w1,dtype=float).reshape(len(words1),1) \\\n",
    "                                         ,np.array(concs_w2).reshape(len(words1),1),np.array(concQs).reshape(len(words1),1) \\\n",
    "                                         ,np.array(Assoc_USFs).reshape(len(words1),1),np.array(SimAssocs333).reshape(len(words1),1) \\\n",
    "                                         ,np.array(SD_SimLexs).reshape(len(words1),1),np.array(SimLex999s).reshape(len(words1),1))\n",
    "                                         ,axis=1,dtype=float)\n",
    "    return np.concatenate((strings,numbers),dtype=object,axis=1)\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f97ae19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_reader(r'C:\\Users\\adity\\DL4NLP\\hw02\\SimLex-999\\SimLex-999.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e082915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simlex-999-based similarities for (happy,cheerful) is : [[9.55]]\n",
      "Simlex-999-based similarities for (happy,young) is : [[2.0]]\n",
      "Simlex-999-based similarities for (happy,angry) is : [[1.28]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Simlex-999-based similarities for (happy,cheerful) is : {}\".format(data[np.where((data[:,0]=='happy') & (data[:,1]=='cheerful')),3]))\n",
    "print(\"Simlex-999-based similarities for (happy,young) is : {}\".format(data[np.where((data[:,0]=='happy') & (data[:,1]=='young')),3]))\n",
    "print(\"Simlex-999-based similarities for (happy,angry) is : {}\".format(data[np.where((data[:,0]=='happy') & (data[:,1]=='angry')),3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1adc6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c1c77",
   "metadata": {},
   "source": [
    "*Function to build the euclidean distance betwen each word pair*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0739e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_bw_each_pair(vec1,vec2):\n",
    "    dist = np.empty((1,1),dtype=float)\n",
    "    #print(vec1.shape)\n",
    "    #for i in range(len(vec1)):\n",
    "        #dist = dist + (vec1[i] - vec2[i])**2\n",
    "    dist = np.sum((vec1 - vec2)**2)\n",
    "    #print(dist)\n",
    "    \n",
    "    return np.sqrt(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f318279a",
   "metadata": {},
   "source": [
    "*Function to build the euclidean distance between all pairs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a63aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dist_bw_all_pairs(data):\n",
    "\n",
    "    dist_words = np.empty((999,1),dtype=float)\n",
    "    for i in  range(data.shape[0]):\n",
    "    \n",
    "        dist_words[i,0] = dist_bw_each_pair(wv_from_bin[data[i,0]],wv_from_bin[data[i,1]])\n",
    "        \n",
    "    return np.concatenate((np.array(data[:,0]).reshape(len(data),1),np.array(data[:,1]).reshape(len(data),1),np.array(dist_words)),axis=1,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b7befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = dist_bw_all_pairs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6dd0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec-based distances between the pairs (happy, cheerful) is : [[2.9259684085845947]]\n",
      "word2vec-based distances between the pairs (happy, young) is : [[2.9159836769104004]]\n",
      "word2vec-based distances between the pairs (happy, angry) is : [[2.874587059020996]]\n"
     ]
    }
   ],
   "source": [
    "print(\"word2vec-based distances between the pairs (happy, cheerful) is : {}\" \\\n",
    "      .format(distances[np.where((distances[:,0]=='happy')& (distances[:,1]=='cheerful')),2]))\n",
    "print(\"word2vec-based distances between the pairs (happy, young) is : {}\" \\\n",
    "      .format(distances[np.where((distances[:,0]=='happy')& (distances[:,1]=='young')),2]))\n",
    "print(\"word2vec-based distances between the pairs (happy, angry) is : {}\" \\\n",
    "      .format(distances[np.where((distances[:,0]=='happy')& (distances[:,1]=='angry')),2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a36f1",
   "metadata": {},
   "source": [
    "*We do pearson coefficient analysis on the two similarity scores of simlex-999 and the similarity score we derived above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "74af784f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3474894638818695, 9.970478185540422e-30)"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.pearsonr(distances[:,2],data[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118de907",
   "metadata": {},
   "source": [
    "*From the above scores we can see that there is a moderate relationship between the two scores*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
