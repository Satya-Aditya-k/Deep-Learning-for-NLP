{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178ca5e0",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c397d9",
   "metadata": {},
   "source": [
    "*In this programming exercise we take the polarity dataset and build a perceptron using only numpy with only one layer to train the model and try to get the accuracy above 70%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2506d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#               5.1 DATASET READER\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "rawdev = open(\"DATA/rt-polarity.dev.vecs\").read()\n",
    "rawtrain = open(\"DATA/rt-polarity.train.vecs\").read()\n",
    "rawtest = open(\"DATA/rt-polarity.train.vecs\").read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f094d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df):\n",
    "    \n",
    "\n",
    "    #extract labels from file\n",
    "    \n",
    "    df_parsed = df.replace('\\t','\\n').split('\\n')\n",
    "    df_label = df_parsed[1::3]\n",
    "    labels = np.array(list(map(lambda x:1 if x == 'label=POS' else 0, df_label)),dtype=int)\n",
    "    labels = labels.reshape(len(labels),1)\n",
    "    \n",
    "    #extract reviews as np.array from file\n",
    "    \n",
    "    review = df_parsed[2::3]\n",
    "    review = np.array(review,dtype=str)\n",
    "    \n",
    "    review_num = {}\n",
    "    \n",
    "    for x in range(len(review)):\n",
    "        review_num[x] = np.array(list(map(lambda x:x.replace(\"'\", \"\"), review[x].split())),dtype=float,order='K')\n",
    "    \n",
    "    train = np.zeros((len(labels),100))\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        train[i]= review_num[i].flatten().reshape(1,100)\n",
    "    \n",
    "    #adding bias to the data and concatenating the features and bias \n",
    "    \n",
    "    bias = np.ones((len(labels),1),dtype=float)\n",
    "    x = np.concatenate((train,bias),axis=1)\n",
    "    \n",
    "    return x,labels\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c2e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features and labels from all 3 datasets\n",
    "\n",
    "x_dev,labels_dev = extract_data(rawdev)\n",
    "x_train,labels_train = extract_data(rawtrain)\n",
    "x_test,labels_test = extract_data(rawtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94efba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#               5.2 NUMPY IMPLEMENTATION\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#function for sigmoid activation function\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z ))\n",
    "    return s\n",
    "\n",
    "#function for derivative of sigmoid activation function\n",
    "\n",
    "def sigmoid_derv(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s*(1-s)\n",
    "\n",
    "#function for finding accuracy of a model.\n",
    "\n",
    "def accuracy(x,w,actual):\n",
    "    \n",
    "    y_est = np.empty((len(x),1))\n",
    "    \n",
    "    #estimating labels based on the threshold of 0.5 on the output of act.function\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        z = np.dot(x[i].T,w)\n",
    "        if sigmoid(z)<0.5:\n",
    "            y_est[i] = 0\n",
    "        else:\n",
    "            y_est[i] = 1\n",
    "        \n",
    "    right=0\n",
    "    \n",
    "    #computing the accuracy of the outputs\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        if y_est[i]==actual[i]:\n",
    "            right+=1\n",
    "    accuracy = right/len(actual)*100\n",
    "    return accuracy\n",
    "\n",
    "#function for squared loss of the estimated labels\n",
    "\n",
    "def squared_loss(x,w,actual):\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(len(actual)):\n",
    "        loss += (sigmoid(np.dot(x[i].T,w))-actual[i])**2\n",
    "    return np.array(loss,dtype=int)\n",
    "\n",
    "\n",
    "def perceptron_model(df,alpha,batch,epochs,y):\n",
    "    \n",
    "    batch_1 = batch-1\n",
    "    w_sum = np.zeros((101,1),dtype=float)\n",
    "    rng = np.random.RandomState(200)\n",
    "    w = rng.normal(0,1,(101,1))\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        for j in range(df.shape[0]):\n",
    "            z = np.dot(df[j].T,w)\n",
    "            y_estim = sigmoid(z)\n",
    "            w_sum += (y_estim-y[j])*sigmoid_derv(z)*df[j].reshape(101,1) #summation of weights of each mini-batch\n",
    "            if j%batch==batch_1:        #conditon to update the weights only at the end of each batch\n",
    "                w -= (alpha*w_sum)/batch\n",
    "                w_sum = np.zeros((101,1),dtype=float) # clearing the accumulated weights after each epoch\n",
    "            if j==df.shape[0]-1:                 #updating the weight at the end of each dataset\n",
    "                w = w - (alpha*w_sum)/batch\n",
    "    \n",
    "    return w\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5af20d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:/Users/adity/AppData/Local/Temp/xpython_15472/2272818522.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1/(1+np.exp(-z ))\n",
      "C:/Users/adity/AppData/Local/Temp/xpython_15472/2272818522.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of dev set: 66.79174484052533\n",
      "Squared loss of dev set: [527]\n",
      "accuracy of test set: 68.32797427652733\n",
      "Squared loss of test set: [2333]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#               5.3 TRAINING\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "weights = perceptron_model(df=x_train,alpha=0.01,batch=10,epochs=59,y=labels_train)\n",
    "\n",
    "print(\"accuracy of dev set: {}\".format(accuracy(x_dev,weights,labels_dev)))\n",
    "print(\"Squared loss of dev set: {}\".format(squared_loss(x_dev,weights,labels_dev)))\n",
    "\n",
    "\n",
    "print(\"accuracy of test set: {}\".format(accuracy(x_test,weights,labels_test)))\n",
    "print(\"Squared loss of test set: {}\".format(squared_loss(x_test,weights,labels_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_accu(df,alpha,batch,y,x_test,labels_test):\n",
    "    epochs= 0\n",
    "    batch_1 = batch-1\n",
    "    w_sum = np.zeros((101,1),dtype=float)\n",
    "    rng = np.random.RandomState(200)\n",
    "    w = rng.normal(0,1,(101,1))\n",
    "    \n",
    "    while 1!=0:\n",
    "        #print(\"epoch {} running\".format(i))\n",
    "        #rng.shuffle(df)\n",
    "        epochs+=1\n",
    "        for j in range(df.shape[0]):\n",
    "            z = np.dot(df[j].T,w)\n",
    "            y_estim = sigmoid(z)\n",
    "            w_sum += (y_estim-y[j])*sigmoid_derv(z)*df[j].reshape(101,1) #summation of weights of each mini-batch\n",
    "            if j%batch==batch_1:        #conditon to update the weights only at the end of each batch\n",
    "                w -= (alpha*w_sum)/batch\n",
    "                w_sum = np.zeros((101,1),dtype=float) # clearing the accumulated weights after each epoch\n",
    "            if j==df.shape[0]-1:                 #updating the weight at the end of each dataset\n",
    "                w = w - (alpha*w_sum)/batch\n",
    "        \n",
    "        if accuracy(x_dev,w,labels_dev)>=74:\n",
    "            print(\"epoch : {} weights: {} accuracy: {}\".format(epochs,w,accuracy(x_test,w,labels_test)))\n",
    "            break\n",
    "            \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c155ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
